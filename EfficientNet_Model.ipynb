{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/project/SDS/capstones_tashman/tumor_control/data/b/deep l\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet Model\n",
    "\n",
    "Training Time: 2471 sec \n",
    "\n",
    "87% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Attempting to install pillow-webp-fork...\n",
      "Could not install WebP support: Command '['pip', 'install', 'pillow-webp-fork']' returned non-zero exit status 1.\n",
      "WEBP images might not load correctly.\n",
      "Downloading dataset from Kaggle...\n",
      "Dataset downloaded to: /home/gry6ks/.cache/kagglehub/datasets/sumn2u/garbage-classification-v2/versions/8\n",
      "Using data directory: /home/gry6ks/.cache/kagglehub/datasets/sumn2u/garbage-classification-v2/versions/8/garbage-dataset\n",
      "Scanning dataset for valid images...\n",
      "Processing class: battery (944 files)\n",
      "Processing class: biological (997 files)\n",
      "Processing class: cardboard (1825 files)\n",
      "Processing class: clothes (5327 files)\n",
      "Processing class: glass (3061 files)\n",
      "Processing class: metal (1020 files)\n",
      "Processing class: paper (1680 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3296: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: plastic (1984 files)\n",
      "Processing class: shoes (1977 files)\n",
      "Processing class: trash (947 files)\n",
      "Skipped 3 corrupt or unreadable images.\n",
      "\n",
      "Class distribution (Valid images):\n",
      "  battery: 944 images\n",
      "  biological: 997 images\n",
      "  cardboard: 1825 images\n",
      "  clothes: 5327 images\n",
      "  glass: 3061 images\n",
      "  metal: 1020 images\n",
      "  paper: 1677 images\n",
      "  plastic: 1984 images\n",
      "  shoes: 1977 images\n",
      "  trash: 947 images\n",
      "\n",
      "Found 19759 valid images across 10 classes.\n",
      "Loaded 10 classes: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'metal', 'paper', 'plastic', 'shoes', 'trash']\n",
      "Total dataset size: 19759 valid images\n",
      "\n",
      "Class weights for balanced sampling:\n",
      "  battery (Index 0): 2.0931\n",
      "  biological (Index 1): 1.9818\n",
      "  cardboard (Index 2): 1.0827\n",
      "  clothes (Index 3): 0.3709\n",
      "  glass (Index 4): 0.6455\n",
      "  metal (Index 5): 1.9372\n",
      "  paper (Index 6): 1.1782\n",
      "  plastic (Index 7): 0.9959\n",
      "  shoes (Index 8): 0.9994\n",
      "  trash (Index 9): 2.0865\n",
      "\n",
      "Splitting dataset:\n",
      "  Total: 19759\n",
      "  Train: 13833\n",
      "  Validation: 2963\n",
      "  Test: 2963\n",
      "\n",
      "Visualizing some training samples...\n",
      "Saved sample visualization to training_samples.png\n",
      "Using EfficientNet-B0 with 1280 input features to classifier.\n",
      "Model 'efficientnet_b0' created.\n",
      "Freezing backbone layers...\n",
      "Trainable parameters after freezing: 664,586\n",
      "\n",
      "--- Starting Training ---\n",
      "Total epochs: 30, Initial LR: 0.0003, Patience: 7\n",
      "Mixup: True (alpha=0.2), Label Smoothing: 0.1\n",
      "Backbone unfreeze epoch: 5\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 9.2265, Train Acc: 39.18%\n",
      "  Valid Loss: 4.3591, Valid Acc: 71.01%\n",
      "  LR: 3.00e-04\n",
      "  Validation loss improved (inf -> 4.3591). Saving best loss model...\n",
      "  Validation accuracy improved (0.00% -> 71.01%). Saving best accuracy model...\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 7.0080, Train Acc: 50.08%\n",
      "  Valid Loss: 8.3847, Valid Acc: 74.38%\n",
      "  LR: 2.99e-04\n",
      "  Validation accuracy improved (71.01% -> 74.38%). Saving best accuracy model...\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 6.2006, Train Acc: 52.69%\n",
      "  Valid Loss: 5.5444, Valid Acc: 77.42%\n",
      "  LR: 2.97e-04\n",
      "  Validation accuracy improved (74.38% -> 77.42%). Saving best accuracy model...\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 5.7507, Train Acc: 53.34%\n",
      "  Valid Loss: 3.4680, Valid Acc: 77.66%\n",
      "  LR: 2.93e-04\n",
      "  Validation loss improved (4.3591 -> 3.4680). Saving best loss model...\n",
      "  Validation accuracy improved (77.42% -> 77.66%). Saving best accuracy model...\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 5.3267, Train Acc: 54.30%\n",
      "  Valid Loss: 3.1354, Valid Acc: 77.76%\n",
      "  LR: 2.87e-04\n",
      "  Validation loss improved (3.4680 -> 3.1354). Saving best loss model...\n",
      "  Validation accuracy improved (77.66% -> 77.76%). Saving best accuracy model...\n",
      "\n",
      "Epoch 6/30\n",
      "\n",
      "--- Unfreezing backbone at epoch 6 ---\n",
      "Unfreezing all backbone layers...\n",
      "Trainable parameters after unfreezing: 4,672,134 / 4,672,134 (100.00%)\n",
      "Updating optimizer for fine-tuning. New LR: 2.9999999999999997e-05\n",
      "Scheduler reset. T_max=25, eta_min=3.00e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 6.0539, Train Acc: 49.65%\n",
      "  Valid Loss: 5.4033, Valid Acc: 81.30%\n",
      "  LR: 3.00e-05\n",
      "  Validation accuracy improved (77.76% -> 81.30%). Saving best accuracy model...\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 5.7239, Train Acc: 51.10%\n",
      "  Valid Loss: 3.0360, Valid Acc: 81.07%\n",
      "  LR: 2.99e-05\n",
      "  Validation loss improved (3.1354 -> 3.0360). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 5.5262, Train Acc: 51.29%\n",
      "  Valid Loss: 2.4924, Valid Acc: 82.21%\n",
      "  LR: 2.95e-05\n",
      "  Validation loss improved (3.0360 -> 2.4924). Saving best loss model...\n",
      "  Validation accuracy improved (81.30% -> 82.21%). Saving best accuracy model...\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 5.3841, Train Acc: 51.13%\n",
      "  Valid Loss: 2.5123, Valid Acc: 81.57%\n",
      "  LR: 2.90e-05\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 5.0823, Train Acc: 52.78%\n",
      "  Valid Loss: 2.4834, Valid Acc: 83.43%\n",
      "  LR: 2.82e-05\n",
      "  Validation loss improved (2.4924 -> 2.4834). Saving best loss model...\n",
      "  Validation accuracy improved (82.21% -> 83.43%). Saving best accuracy model...\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.9333, Train Acc: 52.59%\n",
      "  Valid Loss: 2.2304, Valid Acc: 84.34%\n",
      "  LR: 2.72e-05\n",
      "  Validation loss improved (2.4834 -> 2.2304). Saving best loss model...\n",
      "  Validation accuracy improved (83.43% -> 84.34%). Saving best accuracy model...\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.7752, Train Acc: 53.18%\n",
      "  Valid Loss: 1.9928, Valid Acc: 82.15%\n",
      "  LR: 2.60e-05\n",
      "  Validation loss improved (2.2304 -> 1.9928). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.5408, Train Acc: 54.43%\n",
      "  Valid Loss: 2.0997, Valid Acc: 84.75%\n",
      "  LR: 2.46e-05\n",
      "  Validation accuracy improved (84.34% -> 84.75%). Saving best accuracy model...\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.4551, Train Acc: 54.32%\n",
      "  Valid Loss: 1.8575, Valid Acc: 85.12%\n",
      "  LR: 2.31e-05\n",
      "  Validation loss improved (1.9928 -> 1.8575). Saving best loss model...\n",
      "  Validation accuracy improved (84.75% -> 85.12%). Saving best accuracy model...\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.3507, Train Acc: 54.22%\n",
      "  Valid Loss: 1.9647, Valid Acc: 85.25%\n",
      "  LR: 2.15e-05\n",
      "  Validation accuracy improved (85.12% -> 85.25%). Saving best accuracy model...\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.2220, Train Acc: 54.88%\n",
      "  Valid Loss: 1.7146, Valid Acc: 85.86%\n",
      "  LR: 1.97e-05\n",
      "  Validation loss improved (1.8575 -> 1.7146). Saving best loss model...\n",
      "  Validation accuracy improved (85.25% -> 85.86%). Saving best accuracy model...\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 4.2473, Train Acc: 53.58%\n",
      "  Valid Loss: 1.6635, Valid Acc: 85.32%\n",
      "  LR: 1.79e-05\n",
      "  Validation loss improved (1.7146 -> 1.6635). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.9468, Train Acc: 55.76%\n",
      "  Valid Loss: 1.7887, Valid Acc: 85.18%\n",
      "  LR: 1.61e-05\n",
      "  No improvement in val loss or acc for 2 epoch(s).\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.8698, Train Acc: 56.12%\n",
      "  Valid Loss: 1.6925, Valid Acc: 86.57%\n",
      "  LR: 1.42e-05\n",
      "  Validation accuracy improved (85.86% -> 86.57%). Saving best accuracy model...\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.7805, Train Acc: 56.38%\n",
      "  Valid Loss: 1.5384, Valid Acc: 85.69%\n",
      "  LR: 1.24e-05\n",
      "  Validation loss improved (1.6635 -> 1.5384). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.8346, Train Acc: 55.66%\n",
      "  Valid Loss: 1.5090, Valid Acc: 85.89%\n",
      "  LR: 1.06e-05\n",
      "  Validation loss improved (1.5384 -> 1.5090). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.7574, Train Acc: 55.50%\n",
      "  Valid Loss: 1.5187, Valid Acc: 87.24%\n",
      "  LR: 8.83e-06\n",
      "  Validation accuracy improved (86.57% -> 87.24%). Saving best accuracy model...\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.6043, Train Acc: 56.64%\n",
      "  Valid Loss: 1.5141, Valid Acc: 86.16%\n",
      "  LR: 7.19e-06\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.7598, Train Acc: 54.99%\n",
      "  Valid Loss: 1.4545, Valid Acc: 86.13%\n",
      "  LR: 5.68e-06\n",
      "  Validation loss improved (1.5090 -> 1.4545). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.7429, Train Acc: 55.29%\n",
      "  Valid Loss: 1.3816, Valid Acc: 86.74%\n",
      "  LR: 4.32e-06\n",
      "  Validation loss improved (1.4545 -> 1.3816). Saving best loss model...\n",
      "  No improvement in val loss or acc for 1 epoch(s).\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.6244, Train Acc: 55.40%\n",
      "  Valid Loss: 1.4522, Valid Acc: 86.97%\n",
      "  LR: 3.14e-06\n",
      "  No improvement in val loss or acc for 2 epoch(s).\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.5975, Train Acc: 56.16%\n",
      "  Valid Loss: 1.4667, Valid Acc: 86.26%\n",
      "  LR: 2.14e-06\n",
      "  No improvement in val loss or acc for 3 epoch(s).\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.5373, Train Acc: 56.27%\n",
      "  Valid Loss: 1.5000, Valid Acc: 86.64%\n",
      "  LR: 1.34e-06\n",
      "  No improvement in val loss or acc for 4 epoch(s).\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.5179, Train Acc: 56.28%\n",
      "  Valid Loss: 1.4189, Valid Acc: 86.67%\n",
      "  LR: 7.67e-07\n",
      "  No improvement in val loss or acc for 5 epoch(s).\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.6295, Train Acc: 54.76%\n",
      "  Valid Loss: 1.4760, Valid Acc: 87.07%\n",
      "  LR: 4.17e-07\n",
      "  No improvement in val loss or acc for 6 epoch(s).\n",
      "\n",
      "Training finished after 30 epochs.\n",
      "Loading best model based on validation accuracy...\n",
      "Loaded best model with validation accuracy: 87.24%\n",
      "\n",
      "--- Plotting Training Results ---\n",
      "Saved training plot to training_results.png\n",
      "\n",
      "--- Evaluating Model on Test Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "  Average Loss: 0.4883\n",
      "  Accuracy: 87.14% (2582/2963)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery      0.869     0.974     0.919       116\n",
      "  biological      0.915     0.952     0.933       147\n",
      "   cardboard      0.915     0.881     0.898       295\n",
      "     clothes      0.979     0.950     0.964       780\n",
      "       glass      0.966     0.727     0.830       469\n",
      "       metal      0.531     0.969     0.686       161\n",
      "       paper      0.897     0.798     0.844       262\n",
      "     plastic      0.747     0.845     0.793       297\n",
      "       shoes      0.954     0.909     0.931       297\n",
      "       trash      0.721     0.727     0.724       139\n",
      "\n",
      "    accuracy                          0.871      2963\n",
      "   macro avg      0.849     0.873     0.852      2963\n",
      "weighted avg      0.894     0.871     0.876      2963\n",
      "\n",
      "Saved normalized confusion matrix to confusion_matrix_normalized.png\n",
      "Saved raw confusion matrix to confusion_matrix_raw.png\n",
      "\n",
      "--- Visualizing Predictions on Test Set ---\n",
      "Saved prediction visualization to test_predictions.png\n",
      "\n",
      "--- Execution Finished ---\n",
      "Final Test Accuracy: 87.14%\n",
      "Plots and model checkpoints ('best_model_acc.pth', 'best_model_loss.pth') saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, WeightedRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms.functional import to_pil_image, normalize \n",
    "from tqdm import tqdm\n",
    "import kagglehub\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import subprocess\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "setup_seed(SEED)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TEST_RATIO = 0.15\n",
    "VAL_RATIO = 0.15 \n",
    "NUM_EPOCHS = 30  \n",
    "LEARNING_RATE = 3e-4\n",
    "PATIENCE = 7\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "NUM_WORKERS = 2 \n",
    "UNFREEZE_EPOCH = 5 \n",
    "MIXUP_ALPHA = 0.2 \n",
    "LABEL_SMOOTHING = 0.1 \n",
    "\n",
    "try:\n",
    "    import pkg_resources\n",
    "    try:\n",
    "        pkg_resources.get_distribution('pillow-webp-fork') \n",
    "        print(\"pillow-webp-fork already installed.\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(\"Attempting to install pillow-webp-fork...\")\n",
    "        subprocess.check_call([\"pip\", \"install\", \"pillow-webp-fork\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(\"Successfully installed pillow-webp-fork.\")\n",
    "        print(\"Please restart the kernel/script if WEBP images still cause errors.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not install WebP support: {e}\")\n",
    "    print(\"WEBP images might not load correctly.\")\n",
    "\n",
    "# Download dataset from Kaggle\n",
    "print(\"Downloading dataset from Kaggle...\")\n",
    "dataset_path_root = kagglehub.dataset_download(\"sumn2u/garbage-classification-v2\")\n",
    "print(f\"Dataset downloaded to: {dataset_path_root}\")\n",
    "possible_data_folders = [\"dataset\", \"garbage-dataset\", \"Garbage Classification V2\"]\n",
    "\n",
    "data_dir = None\n",
    "if os.path.exists(os.path.join(dataset_path_root, \"dataset\")):\n",
    "     data_dir = os.path.join(dataset_path_root, \"dataset\")\n",
    "elif os.path.exists(os.path.join(dataset_path_root, \"garbage-dataset\")):\n",
    "     data_dir = os.path.join(dataset_path_root, \"garbage-dataset\")\n",
    "else:\n",
    "    for folder_name in possible_data_folders:\n",
    "        potential_dir = os.path.join(dataset_path_root, folder_name)\n",
    "        if os.path.isdir(potential_dir):\n",
    "            subdirs = [d for d in os.listdir(potential_dir) if os.path.isdir(os.path.join(potential_dir, d))]\n",
    "            if any(cls_name in subdirs for cls_name in ['cardboard', 'glass', 'plastic', 'trash']):\n",
    "                 data_dir = potential_dir\n",
    "                 break\n",
    "    if data_dir is None:\n",
    "        subdirs = [d for d in os.listdir(dataset_path_root) if os.path.isdir(os.path.join(dataset_path_root, d))]\n",
    "        if len(subdirs) == 1:\n",
    "             data_dir = os.path.join(dataset_path_root, subdirs[0])\n",
    "        elif len(subdirs) > 1:\n",
    "             for subdir in subdirs:\n",
    "                 potential_dir = os.path.join(dataset_path_root, subdir)\n",
    "                 sub_subdirs = [d for d in os.listdir(potential_dir) if os.path.isdir(os.path.join(potential_dir, d))]\n",
    "                 if any(cls_name in sub_subdirs for cls_name in ['cardboard', 'glass', 'plastic', 'trash']):\n",
    "                      data_dir = potential_dir\n",
    "                      break\n",
    "if data_dir is None:\n",
    "    print(f\"Warning: Could not reliably determine data directory. Assuming it's: {dataset_path_root}\")\n",
    "    data_dir = dataset_path_root\n",
    "elif not os.path.exists(data_dir):\n",
    "     print(f\"Error: Determined data directory '{data_dir}' does not exist.\")\n",
    "     raise FileNotFoundError(f\"Data directory '{data_dir}' not found.\")\n",
    "\n",
    "print(f\"Using data directory: {data_dir}\")\n",
    "\n",
    "\n",
    "# create a robust dataset class that skips corrupted images\n",
    "class RobustImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.classes = []\n",
    "        self.class_to_idx = {}\n",
    "        self.targets = []\n",
    "\n",
    "        if not os.path.isdir(root):\n",
    "             raise FileNotFoundError(f\"The specified root directory does not exist: {root}\")\n",
    "\n",
    "        try:\n",
    "            potential_classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
    "            if not potential_classes:\n",
    "                raise ValueError(f\"No subdirectories found in {root}. Check the data directory path.\")\n",
    "            self.classes = potential_classes\n",
    "        except OSError as e:\n",
    "             raise OSError(f\"Cannot list directories in {root}. Check permissions or path.\") from e\n",
    "\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        class_counts = {cls: 0 for cls in self.classes}\n",
    "        skipped_count = 0\n",
    "\n",
    "        print(\"Scanning dataset for valid images...\")\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                print(f\"Warning: Expected class directory not found: {class_dir}\")\n",
    "                continue\n",
    "\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            try:\n",
    "                filenames = os.listdir(class_dir)\n",
    "            except OSError as e:\n",
    "                print(f\"Warning: Could not read files in {class_dir}: {e}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing class: {class_name} ({len(filenames)} files)\")\n",
    "\n",
    "            for filename in filenames:\n",
    "                path = os.path.join(class_dir, filename)\n",
    "                if not os.path.isfile(path):\n",
    "                    continue \n",
    "\n",
    "                try:\n",
    "                    with open(path, 'rb') as f:\n",
    "                         img = Image.open(f)\n",
    "                         img.verify() \n",
    "\n",
    "                    self.samples.append((path, class_idx))\n",
    "                    self.targets.append(class_idx)\n",
    "                    class_counts[class_name] += 1\n",
    "                except (UnidentifiedImageError, IOError, OSError, SyntaxError, ValueError) as e:\n",
    "\n",
    "                    skipped_count += 1\n",
    "                except Exception as e: \n",
    "                    print(f\"Unexpected error skipping image {path}: {type(e).__name__} - {e}\")\n",
    "                    skipped_count += 1\n",
    "\n",
    "        if skipped_count > 0:\n",
    "            print(f\"Skipped {skipped_count} corrupt or unreadable images.\")\n",
    "\n",
    "        print(\"\\nClass distribution (Valid images):\")\n",
    "        total_valid = 0\n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"  {cls}: {count} images\")\n",
    "            total_valid += count\n",
    "\n",
    "        if total_valid == 0:\n",
    "             raise RuntimeError(f\"No valid images found in {root}. Please check the dataset content and path.\")\n",
    "\n",
    "        self.targets = np.array(self.targets)\n",
    "        print(f\"\\nFound {total_valid} valid images across {len(self.classes)} classes.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                 sample = Image.open(f).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {path} during getitem: {e}. Returning placeholder.\")\n",
    "\n",
    "            placeholder_tensor = torch.zeros((3, 224, 224), dtype=torch.float32)\n",
    "            return placeholder_tensor, target\n",
    "\n",
    "        if self.transform is not None:\n",
    "            try:\n",
    "                 sample = self.transform(sample)\n",
    "            except Exception as e:\n",
    "                 print(f\"Error applying transform to image {path}: {e}. Returning placeholder.\")\n",
    "                 placeholder_tensor = torch.zeros((3, 224, 224), dtype=torch.float32)\n",
    "                 return placeholder_tensor, target\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Enhanced data transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1), \n",
    "    transforms.RandomGrayscale(p=0.1), \n",
    "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Use the robust dataset\n",
    "try:\n",
    "    dataset_all = RobustImageFolder(data_dir, transform=transform_test)\n",
    "    class_names = dataset_all.classes\n",
    "    print(f\"Loaded {len(class_names)} classes: {class_names}\")\n",
    "    print(f\"Total dataset size: {len(dataset_all)} valid images\")\n",
    "except (FileNotFoundError, ValueError, RuntimeError, OSError) as e:\n",
    "    print(f\"Fatal error loading dataset: {e}\")\n",
    "    raise \n",
    "\n",
    "# Calculate class weights for balanced sampling\n",
    "def calculate_class_weights(targets):\n",
    "    class_sample_count = np.bincount(targets)\n",
    "    class_sample_count = np.maximum(class_sample_count, 1) \n",
    "\n",
    "    total_samples = len(targets)\n",
    "    num_classes = len(class_sample_count)\n",
    "\n",
    "    class_weights = total_samples / (class_sample_count.astype(np.float32) * num_classes)\n",
    "\n",
    "    weights = [class_weights[class_idx] for class_idx in targets]\n",
    "    return weights, class_weights\n",
    "\n",
    "# Calculate weights\n",
    "sample_weights, class_weights_values = calculate_class_weights(dataset_all.targets)\n",
    "print(\"\\nClass weights for balanced sampling:\")\n",
    "for i, cls in enumerate(class_names):\n",
    "    print(f\"  {cls} (Index {i}): {class_weights_values[i]:.4f}\")\n",
    "\n",
    "# Create weighted sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "size_all = len(dataset_all)\n",
    "size_test = int(size_all * TEST_RATIO)\n",
    "size_val = int(size_all * VAL_RATIO)\n",
    "size_train = size_all - size_test - size_val\n",
    "\n",
    "if size_train <= 0 or size_val <= 0 or size_test <= 0:\n",
    "    raise ValueError(\"Calculated split sizes are invalid. Check ratios and dataset size.\")\n",
    "\n",
    "print(f\"\\nSplitting dataset:\")\n",
    "print(f\"  Total: {size_all}\")\n",
    "print(f\"  Train: {size_train}\")\n",
    "print(f\"  Validation: {size_val}\")\n",
    "print(f\"  Test: {size_test}\")\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "# Split using indices because RobustImageFolder applies a default transform\n",
    "# We want to apply train transform only to the train split later\n",
    "indices = list(range(size_all))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:size_train]\n",
    "val_indices = indices[size_train : size_train + size_val]\n",
    "test_indices = indices[size_train + size_val :]\n",
    "\n",
    "# Create subset datasets using indices\n",
    "dataset_train_subset = torch.utils.data.Subset(dataset_all, train_indices)\n",
    "dataset_val_subset = torch.utils.data.Subset(dataset_all, val_indices)\n",
    "dataset_test_subset = torch.utils.data.Subset(dataset_all, test_indices)\n",
    "\n",
    "class TransformedSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.classes = self.subset.dataset.classes\n",
    "        self.class_to_idx = self.subset.dataset.class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the data (which already had the test transform applied by RobustImageFolder)\n",
    "        image_tensor, label = self.subset[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            try:\n",
    "                 # Denormalize first before converting to PIL\n",
    "                 inv_normalize = transforms.Normalize(\n",
    "                     mean=[-m/s for m, s in zip(IMAGENET_MEAN, IMAGENET_STD)],\n",
    "                     std=[1/s for s in IMAGENET_STD]\n",
    "                 )\n",
    "                 image_tensor_denorm = inv_normalize(image_tensor)\n",
    "                 image_pil = to_pil_image(image_tensor_denorm.cpu())\n",
    "                 image = self.transform(image_pil) \n",
    "            except Exception as e:\n",
    "                 print(f\"Error applying specific transform in TransformedSubset for index {idx}: {e}. Returning original tensor.\")\n",
    "                 image = image_tensor\n",
    "        else:\n",
    "             image = image_tensor\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Apply the correct transforms using the wrapper\n",
    "train_dataset = TransformedSubset(dataset_train_subset, transform=transform_train)\n",
    "val_dataset = TransformedSubset(dataset_val_subset, transform=None) \n",
    "test_dataset = TransformedSubset(dataset_test_subset, transform=None) \n",
    "\n",
    "# Create DataLoaders\n",
    "train_subset_targets = dataset_all.targets[train_indices]\n",
    "train_subset_weights, _ = calculate_class_weights(train_subset_targets)\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=train_subset_weights,\n",
    "    num_samples=len(train_subset_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    "    drop_last=True \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "def visualize_samples(dataloader, class_names, num_samples=16, filename='samples.png'):\n",
    "    try:\n",
    "        images, labels = next(iter(dataloader))\n",
    "        num_to_show = min(num_samples, len(images))\n",
    "        if num_to_show == 0:\n",
    "             print(\"Warning: visualize_samples received an empty batch.\")\n",
    "             return\n",
    "\n",
    "        images = images[:num_to_show]\n",
    "        labels = labels[:num_to_show]\n",
    "\n",
    "        n_rows = int(np.sqrt(num_to_show))\n",
    "        n_cols = int(np.ceil(num_to_show / n_rows))\n",
    "\n",
    "        plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "\n",
    "        # Denormalize for display\n",
    "        inv_normalize = transforms.Normalize(\n",
    "            mean=[-m/s for m, s in zip(IMAGENET_MEAN, IMAGENET_STD)],\n",
    "            std=[1/s for s in IMAGENET_STD]\n",
    "        )\n",
    "\n",
    "        for i in range(num_to_show):\n",
    "            plt.subplot(n_rows, n_cols, i + 1)\n",
    "            try:\n",
    "                img_tensor = inv_normalize(images[i]) \n",
    "                img = to_pil_image(img_tensor.cpu()) \n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                # Ensure label index is within bounds\n",
    "                if labels[i].item() < len(class_names):\n",
    "                     plt.title(class_names[labels[i].item()], fontsize=10)\n",
    "                else:\n",
    "                     plt.title(f\"Invalid Label: {labels[i].item()}\", fontsize=10, color='red')\n",
    "\n",
    "            except IndexError:\n",
    "                 print(f\"Error: Label index {labels[i].item()} out of range for class_names (len={len(class_names)})\")\n",
    "                 plt.imshow(np.ones((224, 224, 3)) * 0.5) # Gray placeholder\n",
    "                 plt.axis('off')\n",
    "                 plt.title(\"Label Error\", fontsize=10)\n",
    "            except Exception as e:\n",
    "                print(f\"Error visualizing sample {i}: {e}\")\n",
    "                plt.imshow(np.ones((224, 224, 3)) * 0.5) # Gray placeholder\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Viz Error\", fontsize=10)\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.2, hspace=0.4) # Adjust spacing\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=150) # Save with decent resolution\n",
    "        plt.close()\n",
    "        print(f\"Saved sample visualization to {filename}\")\n",
    "\n",
    "    except StopIteration:\n",
    "        print(\"Error: DataLoader is empty. Cannot visualize samples.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in visualize_samples: {e}\")\n",
    "\n",
    "# Visualize samples before training\n",
    "print(\"\\nVisualizing some training samples...\")\n",
    "visualize_samples(train_loader, class_names, filename='training_samples.png')\n",
    "\n",
    "# Model definition \n",
    "class WasteClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, model_name='efficientnet_b0', dropout_rate=0.4):\n",
    "        super(WasteClassifier, self).__init__()\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if model_name == 'efficientnet_b0':\n",
    "            weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "            self.backbone = models.efficientnet_b0(weights=weights)\n",
    "            self.in_features = self.backbone.classifier[1].in_features\n",
    "            # Replace the final layer with an Identity layer\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            # Get the appropriate preprocessing transform for this model\n",
    "            self.preprocess = weights.transforms()\n",
    "            print(f\"Using EfficientNet-B0 with {self.in_features} input features to classifier.\")\n",
    "\n",
    "        elif model_name == 'resnet50':\n",
    "            weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "            self.backbone = models.resnet50(weights=weights)\n",
    "            self.in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.preprocess = weights.transforms()\n",
    "            print(f\"Using ResNet50 with {self.in_features} input features to classifier.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model name: {model_name}. Choose 'efficientnet_b0' or 'resnet50'.\")\n",
    "\n",
    "        # Custom classifier head with adjusted dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.in_features), # Add BatchNorm before Dropout\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(self.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512), # Add another BatchNorm\n",
    "            nn.Dropout(p=dropout_rate / 2), # Slightly less dropout deeper\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize classifier weights\n",
    "        self._init_weights(self.classifier)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                # Initialize BatchNorm parameters\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        print(\"Freezing backbone layers...\")\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Ensure classifier is trainable\n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"Trainable parameters after freezing: {trainable_params:,}\")\n",
    "\n",
    "    def unfreeze_backbone(self, unfreeze_layers=0):\n",
    "        \"\"\"Unfreezes layers. unfreeze_layers=0 means unfreeze all.\"\"\"\n",
    "        if unfreeze_layers <= 0:\n",
    "             print(\"Unfreezing all backbone layers...\")\n",
    "             for param in self.backbone.parameters():\n",
    "                 param.requires_grad = True\n",
    "        else:\n",
    "            print(f\"Unfreezing the last {unfreeze_layers} layers/blocks of the backbone...\")\n",
    "\n",
    "            named_params = list(self.backbone.named_parameters())\n",
    "            total_layers = len(named_params)\n",
    "            layers_to_unfreeze = named_params[max(0, total_layers - unfreeze_layers):]\n",
    "\n",
    "            print(f\"Total backbone params: {total_layers}. Unfreezing {len(layers_to_unfreeze)} parameter groups.\")\n",
    "\n",
    "            unfrozen_names = []\n",
    "            for name, param in layers_to_unfreeze:\n",
    "                param.requires_grad = True\n",
    "                unfrozen_names.append(name)\n",
    "\n",
    "\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Trainable parameters after unfreezing: {trainable_params:,} / {total_params:,} ({trainable_params/total_params:.2%})\")\n",
    "\n",
    "\n",
    "# Mixup Augmentation Functions\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Applies mixup augmentation.\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0 # No mixup\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Calculates loss for mixup.\"\"\"\n",
    "    loss_a = criterion(pred, y_a)\n",
    "    loss_b = criterion(pred, y_b)\n",
    "    return lam * loss_a + (1 - lam) * loss_b\n",
    "\n",
    "# Training Function (Handles freezing/unfreezing internally)\n",
    "def train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE,\n",
    "               patience=PATIENCE, use_mixup=True, mixup_alpha=MIXUP_ALPHA,\n",
    "               label_smoothing=LABEL_SMOOTHING, weight_decay=WEIGHT_DECAY,\n",
    "               unfreeze_epoch=UNFREEZE_EPOCH, unfreeze_layers=0): # unfreeze_layers=0 means unfreeze all\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss function with label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    # Start with backbone frozen\n",
    "    model.freeze_backbone()\n",
    "    is_frozen = True\n",
    "\n",
    "    # Optimizer (initially only for classifier)\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), # Only pass trainable params\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Scheduler \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=num_epochs, eta_min=learning_rate / 100 # Reduce LR towards the end\n",
    "    )\n",
    "\n",
    "    # Tracking\n",
    "    history = {'train_losses': [], 'val_losses': [], 'train_accuracies': [], 'val_accuracies': []}\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    start_epoch = 0 \n",
    "\n",
    "    print(f\"\\n--- Starting Training ---\")\n",
    "    print(f\"Total epochs: {num_epochs}, Initial LR: {learning_rate}, Patience: {patience}\")\n",
    "    print(f\"Mixup: {use_mixup} (alpha={mixup_alpha}), Label Smoothing: {label_smoothing}\")\n",
    "    print(f\"Backbone unfreeze epoch: {unfreeze_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # --- Unfreezing Logic ---\n",
    "        if is_frozen and epoch >= unfreeze_epoch:\n",
    "            print(f\"\\n--- Unfreezing backbone at epoch {epoch+1} ---\")\n",
    "            model.unfreeze_backbone(unfreeze_layers=unfreeze_layers)\n",
    "            is_frozen = False\n",
    "\n",
    "            # Recreate optimizer with potentially lower LR for fine-tuning all layers\n",
    "            fine_tune_lr = learning_rate / 10\n",
    "            print(f\"Updating optimizer for fine-tuning. New LR: {fine_tune_lr}\")\n",
    "            optimizer = optim.AdamW(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=fine_tune_lr,\n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "\n",
    "            # Reset scheduler for the remaining epochs with the new optimizer and LR\n",
    "            # Adjust T_max for the remaining epochs\n",
    "            remaining_epochs = num_epochs - epoch\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                 optimizer, T_max=remaining_epochs, eta_min=fine_tune_lr / 100\n",
    "            )\n",
    "            print(f\"Scheduler reset. T_max={remaining_epochs}, eta_min={fine_tune_lr / 100:.2e}\")\n",
    "\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        train_bar = tqdm(train_loader, desc=\"[Train]\", leave=False)\n",
    "\n",
    "        for images, labels in train_bar:\n",
    "            try:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Apply Mixup\n",
    "                if use_mixup and not is_frozen:\n",
    "                    images, labels_a, labels_b, lam = mixup_data(images, labels, mixup_alpha)\n",
    "                    outputs = model(images)\n",
    "                    loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    " \n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0) # Weighted by batch size\n",
    "\n",
    "                # Accuracy calculation\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                if use_mixup and not is_frozen:\n",
    "                     correct_train += (lam * (predicted == labels_a).sum().item() + \\\n",
    "                                      (1 - lam) * (predicted == labels_b).sum().item())\n",
    "                else:\n",
    "                    correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "                train_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100*correct_train/total_train:.2f}%\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError during training batch: {e}\")\n",
    "                print(f\"Image shape: {images.shape if 'images' in locals() else 'N/A'}\")\n",
    "                continue \n",
    "\n",
    "        epoch_train_loss = running_loss / total_train if total_train > 0 else 0\n",
    "        epoch_train_acc = 100 * correct_train / total_train if total_train > 0 else 0\n",
    "        history['train_losses'].append(epoch_train_loss)\n",
    "        history['train_accuracies'].append(epoch_train_acc)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        val_bar = tqdm(val_loader, desc=\"[Valid]\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_bar:\n",
    "                try:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels) \n",
    "\n",
    "                    running_loss_val += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100*correct_val/total_val:.2f}%\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError during validation batch: {e}\")\n",
    "                    continue\n",
    "\n",
    "        epoch_val_loss = running_loss_val / total_val if total_val > 0 else float('inf')\n",
    "        epoch_val_acc = 100 * correct_val / total_val if total_val > 0 else 0\n",
    "        history['val_losses'].append(epoch_val_loss)\n",
    "        history['val_accuracies'].append(epoch_val_acc)\n",
    "\n",
    "        print(f\"  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"  Valid Loss: {epoch_val_loss:.4f}, Valid Acc: {epoch_val_acc:.2f}%\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.2e}\") # Display current learning rate\n",
    "\n",
    "        # Update LR scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # --- Checkpointing and Early Stopping ---\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            print(f\"  Validation loss improved ({best_val_loss:.4f} -> {epoch_val_loss:.4f}). Saving best loss model...\")\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), \"best_model_loss.pth\")\n",
    "            epochs_no_improve = 0 # Reset counter\n",
    "\n",
    "\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "             print(f\"  Validation accuracy improved ({best_val_acc:.2f}% -> {epoch_val_acc:.2f}%). Saving best accuracy model...\")\n",
    "             best_val_acc = epoch_val_acc\n",
    "             torch.save(model.state_dict(), \"best_model_acc.pth\")\n",
    "\n",
    "             if epoch_val_loss >= best_val_loss: # Check if loss didn't improve\n",
    "                  epochs_no_improve = 0 # Reset counter as acc improved\n",
    "        elif epoch_val_loss >= best_val_loss: # Only increment if neither loss improved nor acc improved\n",
    "             epochs_no_improve += 1\n",
    "             print(f\"  No improvement in val loss or acc for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs due to no improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    # --- End of Training ---\n",
    "    print(f\"\\nTraining finished after {epoch + 1} epochs.\")\n",
    "    # Load the best model based on validation accuracy\n",
    "    try:\n",
    "        print(\"Loading best model based on validation accuracy...\")\n",
    "        model.load_state_dict(torch.load(\"best_model_acc.pth\", map_location=device))\n",
    "        print(f\"Loaded best model with validation accuracy: {best_val_acc:.2f}%\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: best_model_acc.pth not found. Using the model from the last epoch.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load best accuracy model: {e}. Using the model from the last epoch.\")\n",
    "\n",
    "    history['epochs_trained'] = epoch + 1\n",
    "    return model, history\n",
    "\n",
    "def plot_training_results(history, filename='training_results.png'):\n",
    "    epochs_trained = history.get('epochs_trained', len(history['train_losses']))\n",
    "    if epochs_trained == 0:\n",
    "        print(\"No training history to plot.\")\n",
    "        return\n",
    "\n",
    "    epochs = range(1, epochs_trained + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_losses'], 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, history['val_losses'], 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.ylim(bottom=0) \n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_accuracies'], 'bo-', label='Training Accuracy')\n",
    "    plt.plot(epochs, history['val_accuracies'], 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.ylim(0, 100) # Accuracy is between 0 and 100\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved training plot to {filename}\")\n",
    "\n",
    "# Testing function remains largely the same\n",
    "def test_model(model, test_loader, class_names, criterion=None):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss() # Use standard loss for testing\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    test_bar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_bar:\n",
    "            try:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item() * images.size(0) # Weighted loss\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                test_bar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{100*correct/total:.2f}%\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError during testing batch: {e}\")\n",
    "                continue\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"Error: No test samples were processed.\")\n",
    "        return 0, 0, [], []\n",
    "\n",
    "    avg_test_loss = test_loss / total\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(\"\\n--- Test Results ---\")\n",
    "    print(f\"  Average Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {test_accuracy:.2f}% ({correct}/{total})\")\n",
    "\n",
    "    # Classification Report and Confusion Matrix\n",
    "    if len(all_preds) > 0 and len(all_labels) > 0:\n",
    "        try:\n",
    "            print(\"\\nClassification Report:\")\n",
    "            report = classification_report(all_labels, all_preds, target_names=class_names, digits=3, zero_division=0)\n",
    "            print(report)\n",
    "\n",
    "            # Plot Confusion Matrix (Normalized)\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            cm_norm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], 1e-9) # Avoid division by zero\n",
    "\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues, vmin=0, vmax=1)\n",
    "            plt.title('Normalized Confusion Matrix')\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(class_names))\n",
    "            plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "            plt.yticks(tick_marks, class_names)\n",
    "\n",
    "            fmt = '.2f'\n",
    "            thresh = cm_norm.max() / 2.\n",
    "            for i in range(cm_norm.shape[0]):\n",
    "                for j in range(cm_norm.shape[1]):\n",
    "                    plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                             ha=\"center\", va=\"center\",\n",
    "                             color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            plt.savefig('confusion_matrix_normalized.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(\"Saved normalized confusion matrix to confusion_matrix_normalized.png\")\n",
    "\n",
    "            # Plot Confusion Matrix (Raw Counts)\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Oranges)\n",
    "            plt.title('Confusion Matrix (Raw Counts)')\n",
    "            plt.colorbar()\n",
    "            plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "            plt.yticks(tick_marks, class_names)\n",
    "\n",
    "            fmt = 'd' # Integer format\n",
    "            thresh = cm.max() / 2.\n",
    "            for i in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    plt.text(j, i, format(cm[i, j], fmt),\n",
    "                             ha=\"center\", va=\"center\",\n",
    "                             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            plt.savefig('confusion_matrix_raw.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(\"Saved raw confusion matrix to confusion_matrix_raw.png\")\n",
    "\n",
    "        except ValueError as ve:\n",
    "             print(f\"Error generating classification report/matrix: {ve}\")\n",
    "             print(\"This might happen if some classes are missing from predictions or labels in the test set.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during confusion matrix generation: {e}\")\n",
    "    else:\n",
    "        print(\"Not enough data processed to generate classification report or confusion matrix.\")\n",
    "\n",
    "    return avg_test_loss, test_accuracy, all_preds, all_labels\n",
    "\n",
    "\n",
    "# --- Visualize Predictions Function (Corrected) ---\n",
    "def visualize_predictions(dataloader, class_names, model, num_samples=16, filename='prediction_results.png'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-m/s for m, s in zip(IMAGENET_MEAN, IMAGENET_STD)],\n",
    "        std=[1/s for s in IMAGENET_STD]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Get a batch from the dataloader (test_loader is good for this)\n",
    "        images, labels = next(iter(dataloader))\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        num_to_show = min(num_samples, len(images))\n",
    "        if num_to_show == 0:\n",
    "            print(\"Warning: visualize_predictions received an empty batch.\")\n",
    "            return\n",
    "\n",
    "        images_to_show = images[:num_to_show]\n",
    "        labels_to_show = labels[:num_to_show]\n",
    "\n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images_to_show)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        n_rows = int(np.sqrt(num_to_show))\n",
    "        n_cols = int(np.ceil(num_to_show / n_rows))\n",
    "\n",
    "        plt.figure(figsize=(n_cols * 3.5, n_rows * 3.5)) # Slightly larger figure\n",
    "\n",
    "        for i in range(num_to_show):\n",
    "            plt.subplot(n_rows, n_cols, i + 1)\n",
    "            try:\n",
    "                img_tensor = inv_normalize(images_to_show[i]) # Denormalize\n",
    "                img = to_pil_image(img_tensor.cpu()) # Convert tensor to PIL image\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "\n",
    "                true_label = labels_to_show[i].item()\n",
    "                pred_label = predicted[i].item()\n",
    "\n",
    "                title_color = 'green' if pred_label == true_label else 'red'\n",
    "                title = f\"True: {class_names[true_label]}\\nPred: {class_names[pred_label]}\"\n",
    "                plt.title(title, color=title_color, fontsize=10)\n",
    "            except IndexError:\n",
    "                 plt.imshow(np.ones((224, 224, 3)) * 0.5)\n",
    "                 plt.axis('off')\n",
    "                 plt.title(\"Label/Pred Error\", fontsize=10, color='orange')\n",
    "            except Exception as e:\n",
    "                print(f\"Error visualizing prediction for sample {i}: {e}\")\n",
    "                plt.imshow(np.ones((224, 224, 3)) * 0.5)\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Viz Error\", fontsize=10, color='red')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Saved prediction visualization to {filename}\")\n",
    "\n",
    "    except StopIteration:\n",
    "        print(\"Error: DataLoader is empty. Cannot visualize predictions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in visualize_predictions: {e}\")\n",
    "\n",
    "\n",
    "# === Main Execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Create the model (Using WasteClassifier as defined)\n",
    "        model = WasteClassifier(\n",
    "            num_classes=len(class_names),\n",
    "            model_name='efficientnet_b0', \n",
    "            dropout_rate=0.4 # Adjust dropout if needed\n",
    "        )\n",
    "        print(f\"Model '{model.model_name}' created.\")\n",
    "\n",
    "        # Train the model (handles freezing/unfreezing internally)\n",
    "        model, history = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            patience=PATIENCE,\n",
    "            use_mixup=True, # Enable Mixup\n",
    "            mixup_alpha=MIXUP_ALPHA,\n",
    "            label_smoothing=LABEL_SMOOTHING,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            unfreeze_epoch=UNFREEZE_EPOCH, # Epoch to start fine-tuning backbone\n",
    "            unfreeze_layers=0 # Unfreeze all layers when fine-tuning starts (0 means all)\n",
    "        )\n",
    "\n",
    "        # Plot training results\n",
    "        print(\"\\n--- Plotting Training Results ---\")\n",
    "        plot_training_results(history, filename='training_results.png')\n",
    "\n",
    "        # Test the final model (best one loaded within train_model)\n",
    "        print(\"\\n--- Evaluating Model on Test Set ---\")\n",
    "        test_loss, test_accuracy, _, _ = test_model(model, test_loader, class_names)\n",
    "\n",
    "        # Visualize predictions on a batch from the test set\n",
    "        print(\"\\n--- Visualizing Predictions on Test Set ---\")\n",
    "        # Use test_loader directly for visualization\n",
    "        visualize_predictions(test_loader, class_names, model, filename='test_predictions.png')\n",
    "\n",
    "        print(\"\\n--- Execution Finished ---\")\n",
    "        print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        print(\"Plots and model checkpoints ('best_model_acc.pth', 'best_model_loss.pth') saved.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n--- Fatal Error: File Not Found ---\")\n",
    "        print(f\"{e}\")\n",
    "        print(\"Please ensure the dataset path is correct and the files exist.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n--- Fatal Error: Value Error ---\")\n",
    "        print(f\"{e}\")\n",
    "        print(\"This might be due to incorrect configuration (e.g., split ratios) or dataset issues.\")\n",
    "    except RuntimeError as e:\n",
    "         if \"CUDA out of memory\" in str(e):\n",
    "              print(f\"\\n--- Fatal Error: CUDA Out of Memory ---\")\n",
    "              print(\"Try reducing BATCH_SIZE or using a smaller model.\")\n",
    "         else:\n",
    "              print(f\"\\n--- Fatal Error: Runtime Error ---\")\n",
    "              print(f\"{e}\")\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An Unexpected Error Occurred ---\")\n",
    "        print(f\"Error Type: {type(e).__name__}\")\n",
    "        print(f\"Error Details: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
